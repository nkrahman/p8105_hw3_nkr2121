---
title: "HW3"
author: "Nihaal Rahman (nkr2121)"
due date: "October 14, 2023"
---

```{r, echo = FALSE, message = FALSE}
library(tidyverse)
library(knitr)
library(ggrepel)
```

## Problem 1

Loading in the dataset. 
```{r}
library(p8105.datasets)
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns, with each row representing a single product from an instacart order. There are ID variables indicating the user, order, and product. Other 
variables of interest include order_hour_of_day and days_since_prior_order, which could be useful for seeing
trends among instacart users. In total, there are `r instacart |> select(product_id) |> distinct() |> count()` products found in `r instacart |> select(user_id, order_id) |> distinct() |> count()` orders from `r instacart |> select(user_id) |> distinct() |> count()` distinct users.

How many aisles are there? 
```{r}
instacart |> distinct(aisle) |> count()
```

There are `r instacart |> distinct(aisle) |> count()` aisles in this dataset. 

Which aisles are the most items ordered from?
```{r}
instacart |> 
  count(aisle) |> 
  arrange(desc(n))
```

Now making a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. 
```{r}
instacart |> 
  count(aisle) |> 
  filter(n > 10000) |>
  mutate(aisle = fct_reorder(aisle, n)) |> 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

As you can see through the plot, top 5 aisles for most items ordered from are, in order: fresh vegetables, fresh fruits, packaged vegetables fruits, yogurt, and packaged cheese. 

Now making a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.
```{r}
instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |> 
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(rank = min_rank(desc(n))) |> 
  filter(rank < 4) |> 
  arrange(desc(n)) |>
  knitr::kable()
```

The most popular items from packaged vegetables fruits are: (1) organic baby spinach,
(2) organic raspberries, and (3) organic blueberries. 

The most popular items from baking ingredients are: (1) light brown sugar, (2) pure baking soda, and (3) cane sugar. 

The most popular items from dog food care are: (1) snack sticks chicken & rice recipe dog treats, (2) organix chicken & brown rice recipe, and (3) small dog biscuits. 

Now making a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.
format this table for human readers (i.e. produce a 2 x 7 table).
```{r}
instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |> 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour) |> 
  knitr::kable(digits = 2)
```

Assuming that day 0 = Monday, on average, coffee ice cream was ordered the earliest on Saturdays at 12:26, and latest on Wednesdays at 15:38. Pink lady apples were ordered the earliest on Tuesdays at 11:36, and latest on Thursdays at 14:25. 

## Problem 2

Importing the data
```{r}
data("brfss_smart2010")
```

Data cleaning
```{r}
brfss_smart2010 = brfss_smart2010 |> 
  janitor::clean_names() |> 
  filter(topic == "Overall Health") |> 
  mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", 
                                                "Excellent"), ordered = TRUE)) 
```

In 2002, which states were observed at 7 or more locations? What about in 2010?
```{r}
brfss_smart2010 |> 
  filter(year %in% c(2002, 2010)) |> 
  group_by(year, locationabbr) |> 
  summarize(locationdesc = n_distinct(locationdesc)) |> 
  filter(locationdesc >= 7)
```

In 2002, the following 6 states were observed at 7 or more locations: CT, FL, MA, NC, NJ, and PA. In 2010, the following 14 states were observed at 7 or more locations: CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, and WA. CT is the only state that was observed at 7 or more locations in 2002, but not in 2010. 

Now constructing a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. 
```{r}
data = brfss_smart2010 |> 
  filter(response == "Excellent") |> 
  group_by(locationabbr, year) %>%
  summarize(avg_data_value = mean(data_value, na.rm = TRUE)) |> 
  select(year, locationabbr, avg_data_value)
```

Making a “spaghetti” plot of this average value over time within a state.
```{r}
ggplot(data = data, aes(x = year, y = avg_data_value, group = locationabbr, color = locationabbr)) +
  geom_line(alpha = 0.7) 
```

This plot shows the average value over time within each state. The average data value in 2002 across all states was `r filter(data, year == 2002) |> pull(avg_data_value) |> mean() |> round(2)`. In 2003 the average data value was `r filter(data, year == 2003) |> pull(avg_data_value) |> mean() |> round(2)`. In 2004 the average data value was `r filter(data, year == 2004) |> pull(avg_data_value) |> mean() |> round(2)`. In 2005 the average data value was `r filter(data, year == 2005) |> pull(avg_data_value) |> mean() |> round(2)`. In 2006 the average data value was `r filter(data, year == 2006) |> pull(avg_data_value) |> mean() |> round(2)`. In 2007 the average data value was `r filter(data, year == 2007) |> pull(avg_data_value) |> mean() |> round(2)`. In 2008 the average data value was `r filter(data, year == 2008) |> pull(avg_data_value) |> mean() |> round(2)`. In 2009 the average data value was `r filter(data, year == 2009) |> pull(avg_data_value) |> mean() |> round(2)`. In 2010 the average data value was `r filter(data, year == 2010) |> pull(avg_data_value) |> mean() |> round(2)`.

Making a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.
```{r}
brfss_smart2010 |> 
  filter(locationabbr == "NY" & (year == 2010 | year == 2006)) |> 
  ggplot(aes(x = response, y = data_value, fill = response)) +
  geom_boxplot() +
  facet_grid(~year) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(
    title = "Distribution of Data Value among Locations in NY State",
    x = "Response",
    y = "Data Value",
    fill = "Response"
  )
```

In 2006 and 2010, those who responded "very good" had the highest average data value among all 5 response groups. Likewise, in both years, those who responded "good" were 2nd highest, "excellent" was 3rd highest, "fair" was 4th highest, and "poor" was the lowest. The average values for the "fair", "very good", and "excellent" groups visibly increased from 2006 to 2010. 

## Problem 3

Loading, tidying, merging, and otherwise organizing the data sets.
```{r}
covar <- read_csv("~/Downloads/nhanes_covar.csv", skip = 4)

accel <- read_csv("~/Downloads/nhanes_accel.csv")

merged_data = left_join(covar, accel, by = "SEQN") |>
  janitor::clean_names() |> 
  filter(!is.na(sex) & !is.na(age) & !is.na(bmi) & !is.na(education)) |> 
  filter(age >= 21) |> 
  mutate(sex = ifelse(sex == 1, "male", "female")) |> 
  mutate(education = ifelse(education == 1, "Less than high school", 
                            ifelse(education == 2, "High school equivalent", "More than high school"))) |> 
  mutate(education = factor(education, levels = c("Less than high school", "High school equivalent", "More than high school")))
   
```

Producing a reader-friendly table for the number of men and women in each education category
```{r}
merged_data |> 
  janitor::tabyl(sex, education)
```

Overall, there are more men in this data set than women. Within men and women each, respectively, about half have more than a high school education, and the remaining half is split between less than high school and high school equivalent educations. 

Creating a visualization of the age distributions for men and women in each education category.
```{r}
merged_data |> 
  ggplot(aes(x = education, y = age, fill = education)) +
  geom_boxplot() +
  facet_grid(~sex) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  labs(
    title = "Distribution of Age for Women and Men in Each Education Group",
    x = "Education",
    y = "Age",
    fill = "Age (yrs)"
  )
```

In both men and women, the more than high school group has an younger average age than the other two groups. In women, the average age for the less than high school and high school equivalent group are about the same, but in men, there is a gradient of average ages, getting younger as the educational attainment level increases. 

Using the tidied dataset, aggregating across minutes to create a total activity variable for each participant. Plotting these total activities (y-axis) against age (x-axis), while comparing men to women with separate panels for each education level, and including a smooth to illustrate differences.
```{r}
merged_data %>% 
  mutate(total_activity = rowSums(select(., starts_with("min")), na.rm = TRUE)) |> 
  ggplot(aes(x = age, y = total_activity, color = sex)) +
  facet_grid(~education) +
  geom_point(alpha = .5) +
  geom_smooth(se = FALSE)
```

In the high school equivalent and more than high school groups, women had, on average, a greater total_activity than men for most ages. In the less than high school groups, both men's and women's total activity steeply drops with age. In the high school equivalent group, the average total activity for men and women rises until 40, at which point it declines, but then women experience another slight increase around 60 year. 

Making a three-panel plot that shows the 24-hour activity time courses for each education level and use color to indicate sex. 
```{r}
merged_data |> 
  pivot_longer(cols = starts_with("min"), names_to = "minute", values_to = "activity") |>   mutate(minute = str_remove(minute, "min")) |> 
  mutate(minute = as.numeric(minute)) |> 
  group_by(sex, minute, education) |> 
  summarize(average_activity = mean(activity, na.rm = TRUE)) |>
  ggplot(aes(x = minute, y = average_activity, color = sex)) +
  facet_grid(~education) +
  geom_point(alpha = .3) +
  geom_smooth(se = FALSE)
```
As expected, the average activity is low during the night, and then quickly rises in the morning, and continues to rise until it drops again (presumably when people start going to bed). The average total activity of the less than high school gruoup seems to be higher compared to the other 2 education groups. In all 3 charts, women seem to have a higher average activity than men. 


